import json
import time
from openai import OpenAI, OpenAIError
from app.services.request_log import RequestLogService
import os
import re
from app.lib.logger import logger

chatgpt_api_key = os.environ.get("CHATGPT_API_KEY") or ""


def call_chatgpt_create_caption(images=[], data={}, post_id=0):

    prompt = """[ì—­í• ]  
ë‹¹ì‹ ì€ SNS ìˆí¼ ì½˜í…ì¸  ì „ë¬¸ê°€ì…ë‹ˆë‹¤.  
ì‚¬ìš©ìì˜ Pain Point(ë¶ˆí¸í•¨, ê³ ë¯¼, ë¶ˆë§Œ ë“±)ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ë¬¸ì œë¥¼ ì œì‹œí•˜ê³ ,  
í•´ê²°ì±…ìœ¼ë¡œ ì œí’ˆì„ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì˜ìƒ ì½˜í…ì¸ ë¥¼ ì œì‘í•©ë‹ˆë‹¤.  
hooking, title, descriptionì€ í´ë¦­ ìœ ë„ì™€ SEO ìµœì í™” ëª©ì ì— ë§ì¶° ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.  
ëª¨ë“  ë¬¸ì¥ì€ ì™„ì „í•œ êµ¬ë¬¸ì´ì–´ì•¼ í•˜ë©°, ì´ëª¨í‹°ì½˜ê³¼ ê°íƒ„ì‚¬, ë°ˆ í‘œí˜„ì€ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

[ì…ë ¥ ì •ë³´]  
- ì œí’ˆëª…: {name}  
- ê°€ê²©: {price}  
- ì œí’ˆ ì„¤ëª…: {description}  
- íŒë§¤ì²˜: {store_name}  
- ì œí’ˆ ë§í¬: {base_url}  
- ì œí’ˆ ì†Œê°œ: {text}  

[ì‘ì„± ì¡°ê±´]

hooking:  
- ì´ 4ê°œ ë¬¸ì¥  
- ê° ë¬¸ì¥ 20ì ì´ë‚´  
- ì œí’ˆëª… ì–¸ê¸‰ ì—†ì´ í˜¸ê¸°ì‹¬, í´ë¦­ ìœ ë„, í•œì •ì„±, íŠ¹ê°€ ê°•ì¡° ë“±ìœ¼ë¡œ êµ¬ì„±  
- ì˜ˆì‹œ:  
  - ì§€ê¸ˆë§Œ ëœ¨ëŠ” íŠ¹ê°€, ì•ˆ ë³´ë©´ í›„íšŒí•´ìš”  
  - ëª°ëìœ¼ë©´ ì†í•´ì¼ ë»”í–ˆì£   
  - ë§í¬ íƒ€ê³  ë“¤ì–´ê°€ë©´ ìˆ¨ê²¨ì§„ í˜œíƒ ìˆì–´ìš”  
  - ìš”ì¦˜ ì¸ê¸°í…œ, ì—¬ê¸°ì„œë§Œ ì‹¸ê²Œ íŒ”ì•„ìš”  

title:  
- ìƒí’ˆëª…ë³´ë‹¤ **ì œí’ˆ ì¹´í…Œê³ ë¦¬ ì¤‘ì‹¬ í‚¤ì›Œë“œ** í¬í•¨ (SEO ëª©ì )  
- í•„ìš” ì‹œ ìƒí’ˆëª…ì€ ë¶€ì œì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê²Œ ì‚½ì…  
- ì˜ˆì‹œ:  
  - ì†ëˆˆì¹ ì„¸ëŸ¼ ê³ ë¯¼ ì¤‘ì´ë¼ë©´ ì´ ì œí’ˆ ë³´ì„¸ìš”  
  - ê¸°ë‚´ìš© ìºë¦¬ì–´, ë””ìì¸ì´ ì§„ì§œ ë‹¤ë¦…ë‹ˆë‹¤  

description:  
- ì´ 3ì¤„ êµ¬ì„±  
  1ì¤„: pain ê°•ì¡° + í•´ê²° ì œì•ˆ (ì˜ˆ: ì†ëˆˆì¹ ìˆ± ì ê³  ìê¾¸ ë¹ ì§„ë‹¤ë©´, ì´ ì„¸ëŸ¼ ì¨ë³´ì„¸ìš”)  
  1ì¤„: ë‘˜ì§¸ ì¤„: ê³ ì • í˜•ì‹  
      `"[ì§€ê¸ˆ í´ë¦­í•˜ë©´ ìˆ¨ê²¨ì§„ í• ì¸ ê³µê°œ] {base_url} \n"`
  3ì¤„: {name}  

caption:  
- ê³µë°± í¬í•¨ 750ì ì´ìƒ  
- ìŠ¤í† ë¦¬í…”ë§ êµ¬ì¡°  
- ìµœì†Œ 2ê°€ì§€ ìš”ì†Œ í¬í•¨  
  - ì œí’ˆ ì‚¬ìš© í›„ì˜ ë³€í™”  
  - ê¸°ëŠ¥ì  ì¥ì   
  - ì‚¬íšŒì  ì¦ê±°(í›„ê¸°, ì¬êµ¬ë§¤ ë“±)  
  - ì†Œë¹„ì ë§ì„¤ì„ ì„¤ë“ ìš”ì†Œ  
- êµ¬ì–´ì²´ ë¬¸ì¥, ë§ì¤„ì„í‘œ/ê°íƒ„ì‚¬/ì´ëª¨í‹°ì½˜ ì‚¬ìš© ê¸ˆì§€  
- ë¬¸ì¥ì€ ë°˜ë“œì‹œ ëë§ºê¸°  

hashtag:  
- ì´ 10~15ê°œ  
- {name} í¬í•¨  
- ê¸°ëŠ¥ ê°•ì¡° í‚¤ì›Œë“œ(ì¶”ì²œ, íš¨ê³¼ ë“±) ì œì™¸  
- ì‹¤ì œ ì‚¬ìš©ìê°€ ê²€ìƒ‰í•  ë²•í•œ í‚¤ì›Œë“œ ìœ„ì£¼  
- ë¬¸ì¥í˜•/ë°ˆ/ì§€ë‚˜ì¹˜ê²Œ ê¸´ í•´ì‹œíƒœê·¸ëŠ” ê¸ˆì§€  

[ì¶œë ¥ í˜•ì‹ ì˜ˆì‹œ]
```json
{
    "response": {
        "hooking": [
            "hooking 1",
            "hooking 2",
            ...
        ],
        "caption": "ìµœê·¼ ëª‡ ë…„ê°„, ë§ì€ ì‚¬ëŒë“¤ì´ ìì‹ ì˜ ì™¸ëª¨ë¥¼ ê°œì„ í•˜ê¸° ìœ„í•´ ë‹¤ì–‘í•œ ì œí’ˆê³¼ ì„œë¹„ìŠ¤ë¥¼ ì‹œë„í•˜ê³  ìˆìŠµë‹ˆë‹¤. íŠ¹íˆ, ì†ëˆˆì¹ì€ ì–¼êµ´ì˜ ì¤‘ìš”í•œ ë¶€ë¶„ ì¤‘ í•˜ë‚˜ë¡œ, ë§ì€ ì—¬ì„±ë“¤ì´ ì´ë¥¼ ê°•ì¡°í•˜ê¸° ìœ„í•´ ì†ëˆˆì¹ ì„¸ëŸ¼ì´ë‚˜ ì†ëˆˆì¹ ì˜ì–‘ì œë¥¼ ì‚¬ìš©í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ì œí’ˆë“¤ì€ ì†ëˆˆì¹ì˜ ì„±ì¥ì„ ì´‰ì§„í•˜ê³ , ê±´ê°•í•œ ìƒíƒœë¥¼ ìœ ì§€í•˜ëŠ” ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤.
ì†ëˆˆì¹ ì„¸ëŸ¼ì€ ì£¼ë¡œ ë¹„íƒ€ë¯¼ê³¼ ë¯¸ë„¤ë„ì´ í’ë¶€í•œ ì„±ë¶„ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©°, ì´ëŠ” ì†ëˆˆì¹ì˜ ê±´ê°•ì„ ì¦ì§„ì‹œí‚¤ê³ , ìì—°ìŠ¤ëŸ½ê²Œ ê¸¸ê³  í’ì„±í•˜ê²Œ ë§Œë“œëŠ” ë° íš¨ê³¼ì ì…ë‹ˆë‹¤. ë˜í•œ, ì´ëŸ¬í•œ ì œí’ˆë“¤ì€ ì‚¬ìš©ì´ ê°„í¸í•˜ì—¬, ë§¤ì¼ ë°¤ ì ìë¦¬ì— ë“¤ê¸° ì „ì— ê°„ë‹¨íˆ ë°”ë¥´ê¸°ë§Œ í•˜ë©´ ë©ë‹ˆë‹¤.
ë§ì€ ì‚¬ìš©ìë“¤ì´ ì†ëˆˆì¹ ì„¸ëŸ¼ì„ ì‚¬ìš©í•œ í›„, ëˆˆì— ë„ëŠ” ë³€í™”ë¥¼ ê²½í—˜í–ˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì†ëˆˆì¹ì´ ë” ê¸¸ê³  ë‘êº¼ì›Œì¡Œìœ¼ë©°, ì „ì²´ì ì¸ ì™¸ëª¨ê°€ ë” ë§¤ë ¥ì ìœ¼ë¡œ ë³€í–ˆë‹¤ëŠ” í›„ê¸°ê°€ ë§ìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë³€í™”ëŠ” ìì‹ ê°ì„ ë†’ì—¬ì£¼ê³ , ì¼ìƒìƒí™œì—ì„œ ë” ìì‹  ìˆê²Œ ìƒí™œí•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì¤ë‹ˆë‹¤.
ë˜í•œ, ì†ëˆˆì¹ ì„¸ëŸ¼ì€ ì‚¬íšŒì  ì¦ê±°ë¡œë„ ë’·ë°›ì¹¨ë˜ê³  ìˆìŠµë‹ˆë‹¤. ë§ì€ ìœ ëª… ì¸í”Œë£¨ì–¸ì„œì™€ ë¸”ë¡œê±°ë“¤ì´ ì´ëŸ¬í•œ ì œí’ˆì„ ì‚¬ìš©í•œ í›„, ê¸ì •ì ì¸ ë¦¬ë·°ë¥¼ ë‚¨ê¸°ê³  ìˆìœ¼ë©°, ì´ëŠ” ì œí’ˆì˜ ì‹ ë¢°ì„±ì„ ë†’ì—¬ì¤ë‹ˆë‹¤. ë˜í•œ, ì¬êµ¬ë§¤ìœ¨ì´ ë†’ë‹¤ëŠ” ì ë„ ì œí’ˆì˜ íš¨ê³¼ë¥¼ ì…ì¦í•˜ëŠ” ì¤‘ìš”í•œ ìš”ì†Œì…ë‹ˆë‹¤.
ë”°ë¼ì„œ, ì†ëˆˆì¹ì„ ê°œì„ í•˜ê³ ì í•˜ëŠ” ì‚¬ëŒë“¤ì—ê²Œ ì†ëˆˆì¹ ì„¸ëŸ¼ì€ ë§¤ìš° ì¶”ì²œí•  ë§Œí•œ ì œí’ˆì…ë‹ˆë‹¤. ì´ ì œí’ˆì€ ì‚¬ìš©ì´ ê°„í¸í•˜ê³ , íš¨ê³¼ê°€ ë›°ì–´ë‚˜ë©°, ë§ì€ ì‚¬ìš©ìë“¤ì´ ê¸ì •ì ì¸ ê²½í—˜ì„ í•˜ê³  ìˆë‹¤ëŠ” ì ì—ì„œ í° ì¥ì ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ë§Œì•½ ë‹¹ì‹ ì´ ë” ë§¤ë ¥ì ì¸ ì™¸ëª¨ë¥¼ ì›í•œë‹¤ë©´, ì†ëˆˆì¹ ì„¸ëŸ¼ì„ ì‹œë„í•´ ë³´ëŠ” ê²ƒì€ ì¢‹ì€ ì„ íƒì´ ë  ê²ƒì…ë‹ˆë‹¤.",
        "title": "",
        "description": "Description? \n[ì§€ê¸ˆ í´ë¦­í•˜ë©´ ìˆ¨ê²¨ì§„ í• ì¸ ê³µê°œ] https://example.com \nProduct Name",
        "hashtag": #ì†ëˆˆì¹ì„¸ëŸ¼ #ì†ëˆˆì¹ì˜ì–‘ì œ #ì¿ íŒ¡ì¶”ì²œ #ëˆˆì¹ì¼€ì–´ #ë³€ì‹  #ì†ëˆˆì¹ì„±ì¥ #ì†ëˆˆì¹ê´€ë¦¬ #ì•„ì´ë˜ì‰¬ì„¸ëŸ¼ #ì†ëˆˆì¹ì¼€ì–´ #ê´€ë¦¬ë¹„ê²° #ë‚´ë§˜ì†1ë“± #ì¸ìƒê¿€í…œ #ìê¸°ê´€ë¦¬ #ê´€ë¦¬í•˜ëŠ”ì—¬ì
    }
}

"""
    prompt = replace_prompt_with_data(prompt, data)

    prompt = prompt.replace("CAPTION_COUNT", str(len(images)))

    content = [{"type": "text", "text": prompt}]
    for image in images:
        content.append({"type": "image_url", "image_url": {"url": image}})

    response_schema = {
        "name": "response_schema",
        "strict": True,
        "schema": {
            "type": "object",
            "properties": {
                "response": {
                    "type": "object",
                    "properties": {
                        "hooking": {
                            "type": "array",
                            "description": "hooking message",
                            "items": {"type": "string"},
                        },
                        "caption": {
                            "type": "string",
                            "description": "caption for making video.",
                        },
                        "title": {
                            "type": "string",
                            "description": "Title of the response.",
                        },
                        "description": {
                            "type": "string",
                            "description": "Description text displayed separately from the image on platforms like YouTube, Instagram, and TikTok.",
                        },
                        "hashtag": {
                            "type": "string",
                            "description": "Hashtag associated with the response.",
                        },
                    },
                    "required": [
                        "hooking",
                        "caption",
                        "title",
                        "description",
                        "hashtag",
                    ],
                    "additionalProperties": False,
                }
            },
            "required": ["response"],
            "additionalProperties": False,
        },
    }

    return call_chatgpt(content, response_schema, post_id)


def call_chatgpt_create_blog(images=[], data={}, post_id=0):

    prompt = """ì—…ë¡œë“œëœ ì´ë¯¸ì§€ë“¤ì„ ì°¸ê³ í•˜ì—¬, ì œí’ˆì˜ ë‹¤ìŒ ì„¸ë¶€ ì •ë³´ë¥¼ ë°˜ì˜í•œ ë¸”ë¡œê·¸ ê²Œì‹œê¸€ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”.

[ì—­í• ]  
ë‹¹ì‹ ì€ í•œêµ­ì˜ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.  
ìƒí’ˆì— ë”°ë¼ ê´€ì‹¬ì´ ì£¼ëª©ë  ë§Œí•œ ì—°ë ¹ëŒ€ë¥¼ ì°¾ì•„ì„œ ìµœì ì˜ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”.  
ìœ í–‰ì–´ì™€ ë°ˆ, ê°ì„±ì„ ìê·¹í•˜ì—¬ í•´ë‹¹ ë¸”ë¡œê·¸ì˜ í¬ìŠ¤íŠ¸ë¥¼ í¥ë¯¸ë¡­ê²Œ ë³¼ ìˆ˜ ìˆë„ë¡ ì‹¤ì œ í›„ê¸°ì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê³  ê³µê°ë˜ëŠ” í†¤ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.

[ìƒì„± ì¡°ê±´]  

caption: ì´ ë¸”ë¡œê·¸ ê¸€ì´ ì „ë‹¬í•´ì•¼ í•  ë¶„ìœ„ê¸°, í•µì‹¬ ë©”ì‹œì§€, ì¤‘ì‹¬ ê°ì„±ì„ ê° í•­ëª©ë³„ë¡œ 200~300ìë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”.  
ë‹¹ì‹ ì€ ì´ ìº¡ì…˜ì„ ë°”íƒ•ìœ¼ë¡œ ì „ì²´ ê¸€ì˜ í†¤ì„ ì„¤ì •í•˜ê³ , ì œëª©ê³¼ ì²« ë¬¸ë‹¨ì—ë„ í•´ë‹¹ ê°ì„±ì„ ë°˜ì˜í•©ë‹ˆë‹¤.

ì œí’ˆ ê´€ë ¨ ì •ë³´:  
- ì œí’ˆëª…: {name}  
- ê°€ê²©: {price}  
- ì œí’ˆ ì„¤ëª…: {description}  
- íŒë§¤ì²˜: {store_name}  
- ì œí’ˆ ë§í¬: {base_url}  
  - ë§í¬ëŠ” ë°˜ë“œì‹œ "https://..." í˜•íƒœì˜ ë§í¬ ì£¼ì†Œ ê·¸ ìì²´ê°€ í…ìŠ¤íŠ¸ë¡œ ì¶œë ¥ë˜ë„ë¡ í•˜ì„¸ìš”.  
  - ë‹¤ë¥¸ ë¬¸ì¥ì´ë‚˜ ì œí’ˆëª… ë“±ìœ¼ë¡œ ëŒ€ì²´ëœ í•˜ì´í¼ë§í¬ í˜•ì‹ì€ ê¸ˆì§€í•©ë‹ˆë‹¤.  
  - ì˜ˆì‹œ ì¶œë ¥: https://s.toktak.ai/B0ei2u  
- ì œí’ˆ ì†Œê°œ: {text}

[ê°€ì´ë“œë¼ì¸]:  
- ê²Œì‹œê¸€ì€ ì•½ 2400ì ë¶„ëŸ‰ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.
- ì œí’ˆì˜ íŠ¹ì§•, ì¥ì , ì‚¬ìš© ë°©ë²• ë“±ì„ ì¹œê·¼í•˜ê³  ì§„ì†”í•œ ì–´ì¡°ë¡œ ì „ë‹¬í•´ ì£¼ì„¸ìš”.
- ì•„ë˜ ë‘ ê°€ì§€ í˜•ì‹ìœ¼ë¡œ ê²°ê³¼ë¥¼ ì¶œë ¥í•´ ì£¼ì„¸ìš”:
  1. `docx_content`: í…ìŠ¤íŠ¸ì™€ "IMAGE_URL_0" ê°™ì€ ì´ë¯¸ì§€ ì¸ë±ìŠ¤ë¥¼ í¬í•¨í•œ ë°°ì—´
  2. `content`: HTML í˜•ì‹ì˜ ë³¸ë¬¸ (`<img src="IMAGE_URL_0">` í˜•ì‹ ì‚¬ìš©)  
- ê¸€ì˜ ì‹œì‘ì—ëŠ” ë…ìì˜ ì‹œì„ ì„ ëŒ ìˆ˜ ìˆëŠ” ë§¤ë ¥ì ì¸ ì œëª©(title)ì„ í¬í•¨í•´ ì£¼ì„¸ìš”.  
- ì œëª© ë°”ë¡œ ì•„ë˜ì—ëŠ” ê´‘ê³  ì˜ì—­ ë˜ëŠ” ì•ˆë‚´ ë¬¸êµ¬ë¥¼ ì‚½ì…í•˜ê¸° ìœ„í•´ <h2>ADS_CONTENT_TOKTAK</h2> íƒœê·¸ë¥¼ ë°˜ë“œì‹œ í¬í•¨í•´ ì£¼ì„¸ìš”.
  3. íƒ€ì´í‹€ ì‘ì„± ì§€ì¹¨:  
  - ì œëª©ì—ëŠ” ë§í¬ì£¼ì†Œì˜ ìƒí’ˆëª…ì„ ì§ì ‘ì ìœ¼ë¡œ í¬í•¨í•´ì„œ ì‘ì„±í•˜ì§€ ë§ˆì„¸ìš”. ë°˜ë“œì‹œ ì˜ˆì‹œì™€ ê°™ì´ ì¤€ìˆ˜í•˜ë„ë¡ í•©ë‹ˆë‹¤.
  - ìƒí’ˆì˜ ì¹´í…Œê³ ë¦¬, íŠ¹ì§•, ì‚¬ìš©ì ìƒí™© ë“±ì„ ê¸°ë°˜ìœ¼ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ ë¸”ë¡œê·¸ íƒ€ì´í‹€ë¡œ ì˜ˆì‹œë¥¼ ì°¸ê³ í•˜ì—¬ ì‘ì„±í•´ì£¼ì„¸ìš”.  
  - ì˜ˆì‹œ:  
    - ìŠ¤ìœ„ìŠ¤ë°€ë¦¬í„°ë¦¬ ê¸°ë‚´ìš© ìºë¦¬ì–´ â†’ "ì¸ìƒ ìºë¦¬ì–´ ì¶”ì²œ! ì—¬í–‰ì´ ë‹¬ë¼ì¡Œì–´ìš”"  
    - ë² ì´ê¸€ì—ìŠ¤ ì†ëˆˆì¹ ì„¸ëŸ¼ â†’ "ë‚˜ë§Œì˜ ì†ëˆˆì¹ ë£¨í‹´, ì§„ì§œ íš¨ê³¼ ë´¤ì–´ìš”!"  
    - ë¸”ë£¨ë§ˆí‹´ ìš°ë”” ë¸”ë™ í–¥ìˆ˜ â†’ "ë‚¨ì í–¥ìˆ˜ ê³ ë¯¼ ì¤‘ì´ë¼ë©´? ì´ í–¥ ì¶”ì²œë“œë ¤ìš”"  

- ì´ë¯¸ì§€ëŠ” ì—…ë¡œë“œëœ ëª©ë¡ ì¤‘ ì ì ˆí•œ ê²ƒë“¤ì„ ì„ íƒí•˜ì—¬ ìì—°ìŠ¤ëŸ½ê²Œ ì‚½ì…í•´ ì£¼ì„¸ìš”.  

[ìš”ì•½ë¬¸ ë° í•´ì‹œíƒœê·¸ ì§€ì¹¨]  
- summarizeëŠ” ì‹¤ì œ ì‚¬ìš©ìì˜ 1ì¸ì¹­ í›„ê¸° ìŠ¤íƒ€ì¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.  
  - ì˜ˆ: "ì´ ìºë¦¬ì–´ í•˜ë‚˜ ë°”ê¾¸ê³  ì—¬í–‰ ì¤€ë¹„ê°€ í›¨ì”¬ ì‰¬ì›Œì¡Œì–´ìš”. ê³µí•­ì—ì„œ ëŒê³  ë‹¤ë‹ ë•Œë§ˆë‹¤ ë„ˆë¬´ ë§Œì¡±í•´ìš”~"  

[ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ë‹¤ìš´ êµ¬ì„± í¬ì¸íŠ¸]  
- ìŠ¤í† ë¦¬í…”ë§ ë„ì…ë¶€: ê°œì¸ì ì¸ ê²½í—˜ì´ë‚˜ ê³ ë¯¼ìœ¼ë¡œ ì‹œì‘í•´ ê³µê°ëŒ€ë¥¼ í˜•ì„±í•˜ì„¸ìš”.  
- ì‚¬ìš© ê³„ê¸° + ì²«ì¸ìƒ: ì œí’ˆì„ ì•Œê²Œ ëœ ê³„ê¸°ì™€ ì‚¬ìš©í•´ ë³¸ ì²« ëŠë‚Œì„ ìì—°ìŠ¤ëŸ½ê²Œ ì „ë‹¬í•˜ì„¸ìš”.  
- ì‚¬ìš©ë²• + ì‹¤ì‚¬ìš© í›„ê¸°: ì œí’ˆ ì‚¬ìš© ì¤‘ì˜ ê²½í—˜ì„ ê°ê°ì ìœ¼ë¡œ í‘œí˜„í•˜ê³ , ì¥ì ì„ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.  
- ê°ì •ì˜ íë¦„ í‘œí˜„: â€˜ì²˜ìŒì—” ë°˜ì‹ ë°˜ì˜ â†’ ì¨ë³´ë‹ˆ ë§Œì¡±â€™ ê°™ì€ ì‹¬ë¦¬ ë³€í™”ê°€ ë“œëŸ¬ë‚˜ì•¼ í•©ë‹ˆë‹¤.  
- ìì—°ìŠ¤ëŸ¬ìš´ ë§ˆë¬´ë¦¬: â€˜ì €ì²˜ëŸ¼ ê³ ë¯¼ ì¤‘ì¸ ë¶„ë“¤ê»˜ ë„ì›€ì´ ë ì§€ë„ ëª°ë¼ìš” :)â€™ ê°™ì€ ê°„ì ‘ ì¶”ì²œ í˜•ì‹ìœ¼ë¡œ ë§ˆë¬´ë¦¬í•˜ì„¸ìš”.
- ë§ˆë¬´ë¦¬ í›„ hashtag ë…¸ì¶œ: {name}ì„ í¬í•¨í•œ ì´ 10~15ê°œ í•´ì‹œíƒœê·¸ë¥¼ í•œ ì¤„ ë¬¸ìì—´ë¡œ ì‘ì„±í•˜ì„¸ìš”.(ì¶œë ¥ ì˜ˆì‹œ: #ê¸°ë‚´ìš©ìºë¦¬ì–´, #ì—¬í–‰ê°€ë°©ì¶”ì²œ, #ìŠ¤ìœ„ìŠ¤ë°€ë¦¬í„°ë¦¬, #ê³µí•­íŒ¨ì…˜, #ì—¬í–‰ê°€ë°©, #íŠ¸ë˜ë¸”í•„ìˆ˜í’ˆ, #20ëŒ€ì—¬í–‰í…œ, #ì†Œí˜•ìºë¦¬ì–´ì¶”ì²œ, #ìˆ˜ë‚©ë ¥ì¢‹ì€ìºë¦¬ì–´, #ì—¬í–‰ì•„ì´í…œ)

**docx_content ì‘ì„± ì§€ì¹¨ (í•„ìˆ˜ ì¶œë ¥ í˜•ì‹)**

- `docx_content`ëŠ” ë¸”ë¡œê·¸ ê¸€ì˜ ë³¸ë¬¸ì„ **ë¬¸ë‹¨ ë‹¨ìœ„ë¡œ ë°°ì—´ë¡œ êµ¬ì„±**í•©ë‹ˆë‹¤.  
- ê° í•­ëª©ì€ **í…ìŠ¤íŠ¸** ë˜ëŠ” `"IMAGE_URL_0"` í˜•ì‹ì˜ ì´ë¯¸ì§€ ì¸ë±ìŠ¤ì…ë‹ˆë‹¤.

    1. ê³µê°ê°€ëŠ” ë„ì…ë¶€ (1ì¸ì¹­ ê²½í—˜ë‹´ ì‹œì‘)  
    2. ì œí’ˆì„ ì•Œê²Œ ëœ ê³„ê¸°ì™€ ì²«ì¸ìƒ  
    3. ì‚¬ìš© ë°©ë²• ì„¤ëª…  
    4. ì‹¤ì‚¬ìš© í›„ê¸° ë° ì¥ì   
    5. ì‹¬ë¦¬ ë³€í™” ë¬˜ì‚¬ (ì˜ì‹¬ â†’ ë§Œì¡±)  
    6. ê°„ì ‘ ì¶”ì²œìœ¼ë¡œ ë§ˆë¬´ë¦¬  
    7. ì ì ˆí•œ ìœ„ì¹˜ì— ì´ë¯¸ì§€ ì¸ë±ìŠ¤ ì‚½ì… (ì´ 3~5ì¥)  
    8. **ì œí’ˆ êµ¬ë§¤ ë§í¬ (base_url)** â€“ `https://...` í˜•ì‹ì˜ ì£¼ì†Œë¥¼ **í…ìŠ¤íŠ¸ ê·¸ëŒ€ë¡œ** ì¶œë ¥  
    9. ë§ˆë¬´ë¦¬ í›„ hashtag ë…¸ì¶œ: {name}ì„ í¬í•¨í•œ ì´ 10~15ê°œ í•´ì‹œíƒœê·¸ë¥¼ í•œ ì¤„ ë¬¸ìì—´ë¡œ ì‘ì„±í•˜ì„¸ìš”.(ì¶œë ¥ ì˜ˆì‹œ: #ê¸°ë‚´ìš©ìºë¦¬ì–´, #ì—¬í–‰ê°€ë°©ì¶”ì²œ, #ìŠ¤ìœ„ìŠ¤ë°€ë¦¬í„°ë¦¬, #ê³µí•­íŒ¨ì…˜, #ì—¬í–‰ê°€ë°©, #íŠ¸ë˜ë¸”í•„ìˆ˜í’ˆ, #20ëŒ€ì—¬í–‰í…œ, #ì†Œí˜•ìºë¦¬ì–´ì¶”ì²œ, #ìˆ˜ë‚©ë ¥ì¢‹ì€ìºë¦¬ì–´, #ì—¬í–‰ì•„ì´í…œ)

[í‘œí˜„ ìŠ¤íƒ€ì¼ ì§€ì¹¨ â€“ ì‹¤ì œ ë¸”ë¡œê±° í›„ê¸°ì²˜ëŸ¼ ë³´ì´ë„ë¡]  
- ë°˜ë“œì‹œ 1ì¸ì¹­ ê´€ì ìœ¼ë¡œ ì‘ì„±í•˜ë©°, ë§ˆì¹˜ ë¸”ë¡œê±°ê°€ ìì‹ ì˜ ê²½í—˜ì„ ì´ì•¼ê¸°í•˜ë“¯ ìì—°ìŠ¤ëŸ½ê²Œ ë§í•˜ë“¯ í’€ì–´ì£¼ì„¸ìš”.  
- ê°íƒ„, ë°˜ì „, ìœ ë¨¸, ê³µê° í¬ì¸íŠ¸ë¥¼ ì ê·¹ì ìœ¼ë¡œ ì‚¬ìš©í•´ ì£¼ì„¸ìš”.  
- ì •ë³´ ë‚˜ì—´ì´ ì•„ë‹ˆë¼, ì²´í—˜ ì†ì— ì œí’ˆ ì •ë³´ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ë…¹ì—¬ì„œ ë³´ì—¬ì£¼ì„¸ìš”.  
- â€œì¶”ì²œí•©ë‹ˆë‹¤â€, â€œìµœê³ ì˜ ì„ íƒâ€ ê°™ì€ ê´‘ê³  í‘œí˜„ì€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.

### **ğŸ”¹ Output Format (JSON)**
```json
{
    "title": "ë¸”ë¡œê·¸ ê²Œì‹œê¸€ ì œëª©",
    "summarize": "ìš”ì•½ëœ ë‚´ìš©",
    "docx_content": [
        "ADS_CONTENT_TOKTAK",
        "ì œí’ˆì˜ íŠ¹ì§• ë° ì¥ì ì— ëŒ€í•´ ì„¤ëª…í•˜ëŠ” ì²« ë²ˆì§¸ ë‹¨ë½",
        "IMAGE_URL_0",
        "ì œí’ˆ ì‚¬ìš© ë°©ë²•ì— ëŒ€í•œ ì„¤ëª…ì´ í¬í•¨ëœ ë‘ ë²ˆì§¸ ë‹¨ë½",
        ...,
        "IMAGE_URL_{image_index}",
        "ì œí’ˆì„ êµ¬ë§¤í•˜ëŠ” ë°©ë²•ê³¼ íŒë§¤ì²˜ ì •ë³´",
        "{base_url}",
        "#hashtag1 #hashtag2 #hashtag3"
    ],
    "content": "<h1>ë¸”ë¡œê·¸ ê²Œì‹œê¸€ ì œëª©</h1>
                <h2>ADS_CONTENT_TOKTAK</h2>
                <p>ì œí’ˆì˜ íŠ¹ì§• ë° ì¥ì ì— ëŒ€í•´ ì„¤ëª…í•˜ëŠ” ì²« ë²ˆì§¸ ë‹¨ë½ </p>
                <p><img src="IMAGE_URL_0" alt="{name}"></p>
                <p>ì œí’ˆ ì‚¬ìš© ë°©ë²•ì— ëŒ€í•œ ì„¤ëª…ì´ í¬í•¨ëœ ë‘ ë²ˆì§¸ ë‹¨ë½</p>
                ...etc
                <p><img src="IMAGE_URL_{image_index}" alt="{name}"></p>
                <p>ì œí’ˆì„ êµ¬ë§¤í•˜ëŠ” ë°©ë²•ê³¼ íŒë§¤ì²˜ ì •ë³´</p>
                <p>{base_url}</p>
                <p>#hashtag1 #hashtag2 #hashtag3</p>
}

Note: 

- ì´ ê¸€ì—ëŠ” {count_image}ì¥ì˜ ì‚¬ì§„ë§Œ ë“±ì¥í•©ë‹ˆë‹¤.
"""
    count_image = len(images)
    image_index = count_image - 1
    data["image_index"] = image_index
    data["count_image"] = image_index

    prompt = replace_prompt_with_data(prompt, data)

    content = [{"type": "text", "text": prompt}]
    for image in images:
        content.append({"type": "image_url", "image_url": {"url": image}})

    response_schema = {
        "name": "response_schema",
        "schema": {
            "type": "object",
            "properties": {
                "response": {
                    "type": "object",
                    "properties": {
                        "title": {
                            "type": "string",
                            "description": "The title of the response.",
                        },
                        "summarize": {
                            "type": "string",
                            "description": "A summary or brief overview of the content.",
                        },
                        "docx_content": {
                            "type": "array",
                            "description": "The content will be written to the docx file.",
                            "items": {"type": "string"},
                        },
                        "content": {
                            "type": "string",
                            "description": "The main content of the response.",
                        },
                    },
                    "required": ["title", "summarize", "docx_content", "content"],
                    "additionalProperties": False,
                }
            },
            "required": ["response"],
            "additionalProperties": False,
        },
        "strict": True,
    }

    return call_chatgpt(content, response_schema, post_id)


def call_chatgpt_create_social(images=[], data={}, post_id=0):
    prompt = """[ì—­í• ]  
ë‹¹ì‹ ì€ SNS ë°”ì´ëŸ´ ì½˜í…ì¸  ì œì‘ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.  
ì‚¬ìš©ìì˜ Pain Point(ë¶ˆí¸í•¨, ì•„ì‰¬ì›€, ê³ ë¯¼ ë“±)ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ë¬¸ì œë¥¼ ì œì‹œí•˜ê³ ,  
ì œí’ˆì„ í†µí•´ ìì—°ìŠ¤ëŸ½ê²Œ í•´ê²°í•´ë‚˜ê°€ëŠ” êµ¬ì¡°ë¡œ ì½˜í…ì¸ ë¥¼ ë§Œë“­ë‹ˆë‹¤.  
captionê³¼ descriptionì€ ë…¼ë¦¬ì ìœ¼ë¡œ ì—°ê²°ë˜ê³ , ë§íˆ¬ì™€ ë¶„ìœ„ê¸°ê°€ ì¼ê´€ë˜ì–´ì•¼ í•˜ë©°,  
ëª¨ë“  ë¬¸ì¥ì€ ì‹¤ì œ ì‚¬ìš©ìê°€ ë§í•˜ëŠ” ë“¯í•œ ìì—°ìŠ¤ëŸ¬ìš´ êµ¬ì–´ì²´ë¡œ ì‘ì„±ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.

[ì…ë ¥ ì •ë³´]  
ì œí’ˆëª…: {name}  
ê°€ê²©: {price}  
ì œí’ˆ ì„¤ëª…: {description}  
íŒë§¤ì²˜: {store_name}  
ì œí’ˆ ë§í¬: {base_url}  
ì´ë¯¸ì§€ ê°œìˆ˜: {image_count}  
ì œí’ˆ ì†Œê°œ: {text}  

[ì‘ì„± ì¡°ê±´]  
caption  
- ì´ 5ë¬¸ì¥  
- ê° ë¬¸ì¥ 100ì ì´ë‚´, ì¤„ ìˆ˜ 2ì¤„ ì´í•˜  
- ì „ì²´ íë¦„ êµ¬ì¡°:  
  1. caption1: ì œí’ˆê³¼ ê´€ë ¨ëœ ëŒ€í‘œì ì¸ Pain Point ì œì‹œ  
     - ë‹¨ì •ì ìœ¼ë¡œ ëë‚´ì§€ ë§ê³ , ì˜ë¬¸í˜•, ê°íƒ„í˜•, íƒ„ì‹í˜• ë“±ìœ¼ë¡œ ë§ˆë¬´ë¦¬  
     - ì˜ˆ: â€œì†ëˆˆì¹ ìê¾¸ ë¹ ì§€ëŠ” ê±° ì€ê·¼ ìŠ¤íŠ¸ë ˆìŠ¤ì£ ?â€  
  2. caption2~4: ì œí’ˆ ì‚¬ìš© í›„ ë³€í™”, ì¥ì , ê¸°ëŠ¥ì„ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…  
     - ë¬¸ì¥ ê°„ íë¦„ì€ ë§¤ë„ëŸ½ê²Œ ì´ì–´ì§ˆ ê²ƒ  
  3. caption5: caption1ê³¼ ì—°ê²°ë˜ëŠ” ìˆ˜ë¯¸ìƒê´€í˜• êµ¬ì¡°  
     - ì œí’ˆì˜ ê¸°ëŠ¥ì  ê°€ì¹˜ë¥¼ ë‹´ì•„ ìì—°ìŠ¤ëŸ½ê³  ì„¤ë“ë ¥ ìˆê²Œ ë§ˆë¬´ë¦¬  

description  
- ì´ 3ì¤„ êµ¬ì„±  
  1ì¤„: Pain Killer í˜•ì‹ â€“ ê³ ë¯¼ ê³µê° + ì œí’ˆ ì œì•ˆ (êµ¬ì–´ì²´, ë‹¨ì •ì ì´ì§€ ì•Šê²Œ)  
     ì˜ˆ: "ì†ëˆˆì¹ ë•Œë¬¸ì— ëˆˆí™”ì¥ ë§ì¹œ ì  ìˆë‹¤ë©´, ì´ê±° ì¨ë³´ì„¸ìš”"  
  2ì¤„: [ì§€ê¸ˆ í´ë¦­í•˜ë©´ ìˆ¨ê²¨ì§„ í• ì¸ ê³µê°œ] {base_url}  
  3ì¤„: {name}  
- ì´ëª¨í‹°ì½˜, íŠ¹ìˆ˜ë¬¸ì ì‚¬ìš© ê¸ˆì§€
- ê° ì¤„ì€ "\n" ë¬¸ìë¡œ êµ¬ë¶„ë©ë‹ˆë‹¤  

hashtag  
- ì´ 10~15ê°œ  
- ë°˜ë“œì‹œ #ìœ¼ë¡œ ì‹œì‘  
- {name} í¬í•¨  
- ê¸°ëŠ¥ ê°•ì¡°í˜• í‚¤ì›Œë“œ(ì˜ˆ: ì¶”ì²œ, íš¨ê³¼ ë“±)ëŠ” ì œì™¸  
- ì‹¤ì œ ì‚¬ìš©ìê°€ ê²€ìƒ‰í•  ë§Œí•œ í‚¤ì›Œë“œ ìœ„ì£¼ë¡œ êµ¬ì„±  
- caption ë° descriptionê³¼ ë³„ë„ë¡œ ì¶œë ¥

[ì¶œë ¥ í˜•ì‹ ì˜ˆì‹œ]
{
  "response": {
    "caption": [
      "ë¶€íŒ…ë§Œ 3ë¶„ ê±¸ë¦¬ëŠ” ë…¸íŠ¸ë¶, ì§„ì§œ ë„ˆë¬´ ë‹µë‹µí•˜ì§€ ì•Šë‚˜ìš”?",
      "SSDë¡œ ë°”ê¾¸ê³  ì²´ê° ì†ë„ê°€ ì™„ì „íˆ ë‹¬ë¼ì¡Œì–´ìš”.",
      "ì‘ì—…í•˜ë‹¤ ë©ˆì¶”ëŠ” ì¼ ì—†ì´ ì¾Œì í•˜ê²Œ ì“¸ ìˆ˜ ìˆì—ˆê³ ìš”.",
      "ì˜¤ë˜ëœ ë…¸íŠ¸ë¶ì´ ì´ë ‡ê²Œ ë‹¤ì‹œ ì‚´ì•„ë‚  ì¤„ ëª°ëì–´ìš”.",
      "ë¶€íŒ… ë•Œë¬¸ì— ìŠ¤íŠ¸ë ˆìŠ¤ì˜€ë˜ ë¶„ë“¤, ì´ê±´ ê½¤ ë§Œì¡±í•˜ì‹¤ ê±°ì˜ˆìš”."
    ],
    "description": "ë¶€íŒ…ë§Œ 3ë¶„ ë„˜ê²Œ ê¸°ë‹¤ë¦¬ì…¨ë‹¤ë©´, SSD íƒ‘ì¬ëœ ì´ ë…¸íŠ¸ë¶ ì¨ë³´ì„¸ìš”\n[ì§€ê¸ˆ í´ë¦­í•˜ë©´ ìˆ¨ê²¨ì§„ í• ì¸ ê³µê°œ] https://example.com\nì‚¼ì„± ë…¸íŠ¸ë¶ i5 4ì„¸ëŒ€ 8G SSD 240 NT370E5J",
    "hashtag": "#ì‚¼ì„±ë…¸íŠ¸ë¶ #SSDë…¸íŠ¸ë¶ #ë¶€íŒ…ë¹ ë¥¸ #ì‚¬ë¬´ìš©ë…¸íŠ¸ë¶ #ì¤‘ê³ ë…¸íŠ¸ë¶ #ë¬¸ì„œì‘ì—… #ê°€ì„±ë¹„ë…¸íŠ¸ë¶ #ì—…ë¬´ìš©PC #i5ë…¸íŠ¸ë¶ #ìœˆë„ìš°ë…¸íŠ¸ë¶ #ë…¸íŠ¸ë¶ì¶”ì²œ #ì†ë„ì—… #ì¤‘ê³ PC"
  }
}
"""

    data["image_count"] = len(images)

    prompt = replace_prompt_with_data(prompt, data)

    content = [{"type": "text", "text": prompt}]
    for image in images:
        content.append({"type": "image_url", "image_url": {"url": image}})

    response_schema = {
        "name": "response_schema",
        "schema": {
            "type": "object",
            "properties": {
                "response": {
                    "type": "object",
                    "properties": {
                        "caption": {
                            "type": "array",
                            "description": "caption for making video.",
                            "items": {"type": "string"},
                        },
                        "description": {
                            "type": "string",
                            "description": "The description of the post.",
                        },
                        "hashtag": {
                            "type": "string",
                            "description": "The associated hashtag.",
                        },
                    },
                    "required": ["caption", "description", "hashtag"],
                    "additionalProperties": False,
                }
            },
            "required": ["response"],
            "additionalProperties": False,
        },
        "strict": True,
    }

    return call_chatgpt(content, response_schema, post_id)


def call_chatgpt_clear_product_name(name):
    client = OpenAI(api_key=chatgpt_api_key)
    assistant_id = "asst_EK0uKR3AbhB2Js9cESzqRIxa"
    empty_thread = client.beta.threads.create()
    client.beta.threads.messages.create(
        empty_thread.id,
        role="user",
        content=[{"type": "text", "text": name}],
    )
    run = client.beta.threads.runs.create(
        thread_id=empty_thread.id, assistant_id=assistant_id
    )
    while True:
        run = client.beta.threads.runs.retrieve(
            run_id=run.id, thread_id=empty_thread.id
        )
        if run.status == "completed":
            break

    thread_messages = client.beta.threads.messages.list(empty_thread.id)
    for message in thread_messages:
        if message.role == "assistant":
            return message.content[0].text.value
    return name


def call_chatgpt_get_main_text_and_color_for_image(
    input_text, requested_fields, post_id=0
):
    prompt = """ë‹¹ì‹ ì€ ìƒ‰ìƒ ë””ìì¸ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ìš”êµ¬ ì‚¬í•­ì„ ì¶©ì¡±í•˜ëŠ” ìƒ‰ìƒ íŒ”ë ˆíŠ¸ë¥¼ ë§Œë“¤ì–´ ì£¼ì„¸ìš”.

1. **ì£¼ìš” í…ìŠ¤íŠ¸ ìƒ‰ìƒ (`main_text_color`)**: ë°ê³  ëˆˆê¸¸ì„ ë„ëŠ” ìƒ‰ìƒì´ë©°, ì—´ëŒ€ì ì¸ ëŠë‚Œì´ ë‚˜ëŠ” ìƒ‰ìƒì„ ì„ íƒí•˜ì„¸ìš”.  
2. **ë³´ì¡° í…ìŠ¤íŠ¸ ìƒ‰ìƒ**: í•­ìƒ í°ìƒ‰ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.  
3. **ë°°ê²½ ìƒ‰ìƒ (`background`)**: ì£¼ìš” í…ìŠ¤íŠ¸ ìƒ‰ìƒ ë° ë³´ì¡° í…ìŠ¤íŠ¸(í°ìƒ‰)ì™€ ì¢‹ì€ ëŒ€ë¹„ë¥¼ ì´ë£¨ëŠ” ë°ì€ ìƒ‰ìƒì„ ì„ íƒí•˜ì„¸ìš”.  
4. **ë°°ê²½ ìƒ‰ìƒì´ ë„ˆë¬´ ë‹¨ì¡°ë¡­ê±°ë‚˜ í°ìƒ‰ê³¼ ë¹„ìŠ·í•˜ì§€ ì•Šë„ë¡ ì£¼ì˜í•˜ì„¸ìš”. "ì—°í•œ ë¶„í™", "ì—°í•œ ë…¸ë‘" ë“±ì˜ ìƒ‰ìƒì´ ì ì ˆí•©ë‹ˆë‹¤.**  

ë˜í•œ, ì•„ë˜ì˜ ë¬¸ì¥ì„ ì œê³µí•©ë‹ˆë‹¤. ì´ ë¬¸ì¥ì—ì„œ í•µì‹¬ ë‚´ìš©ì„ ì°¾ì•„ `main_text` ê°’ìœ¼ë¡œ ì‚¬ìš©í•˜ì„¸ìš”.  

"{input_text}"  

ì œê°€ ì›í•˜ëŠ” ë°ì´í„° í•„ë“œëŠ” `{requested_fields}` ì…ë‹ˆë‹¤.  

**ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ì„¸ìš” (ìš”ì²­í•œ í•„ë“œë§Œ í¬í•¨)**:
```json
{
    "main_text": "ë¬¸ì¥ì˜ í•µì‹¬ ë‚´ìš©",
    "main_text_color": "", // ì˜ˆ: "#FF5733"
    "background": "" // ì˜ˆ: "#FFF9C4"
}

"""
    prompt = replace_prompt_with_data(
        prompt, {"input_text": input_text, "requested_fields": requested_fields}
    )

    response_schema = {
        "name": "response_schema",
        "schema": {
            "type": "object",
            "properties": {
                "main_text": {
                    "type": "string",
                    "description": "Main Text",
                },
                "main_text_color": {
                    "type": "string",
                    "description": "Main Text Color",
                },
                "background_color": {
                    "type": "string",
                    "description": "Background Color",
                },
            },
            "required": ["main_text", "main_text_color", "background_color"],
            "additionalProperties": False,
        },
        "strict": True,
    }
    return call_chatgpt(prompt, response_schema, post_id)


def replace_prompt_with_data(prompt, data):
    for key, value in data.items():
        prompt = prompt.replace("{" + key + "}", str(value))
    return prompt


def call_chatgpt(
    content, response_schema, post_id=0, base_prompt=None, temperature=0.9, retry=0
):
    client = OpenAI(api_key=chatgpt_api_key)
    model = "gpt-4o-mini"

    messages = []
    if base_prompt:
        messages.append({"role": "system", "content": base_prompt})
    messages.append({"role": "user", "content": content})

    request_log = json.dumps(
        {
            "model": model,
            "messages": messages,
            "response_format": {
                "type": "json_schema",
                "json_schema": response_schema,
            },
            "max_tokens": 16384,
            "temperature": temperature,
        }
    )

    try:
        response = client.chat.completions.create(
            model=model,
            messages=[
                {
                    "role": "user",
                    "content": content,
                }
            ],
            response_format={
                "type": "json_schema",
                "json_schema": response_schema,
            },
            max_tokens=16384,
            temperature=0.9,
        )
        response_log = json.dumps(response.to_dict())

        if response:
            content = response.choices[0].message.content or None
            usage = response.usage
            prompt_tokens = usage.prompt_tokens
            completion_tokens = usage.completion_tokens
            prompt_cache_tokens = usage.prompt_tokens_details.cached_tokens
            prompt_audio_tokens = usage.prompt_tokens_details.audio_tokens
            completion_reasoning_tokens = (
                usage.completion_tokens_details.reasoning_tokens
            )
            completion_audio_tokens = usage.completion_tokens_details.audio_tokens
            completion_accepted_prediction_tokens = (
                usage.completion_tokens_details.accepted_prediction_tokens
            )
            completion_rejected_prediction_tokens = (
                usage.completion_tokens_details.rejected_prediction_tokens
            )
            total_tokens = usage.total_tokens

            status = 1
            if not content:
                status = 0
            RequestLogService.create_request_log(
                post_id=post_id,
                ai_type="chatgpt",
                request=request_log,
                response=response_log,
                prompt_tokens=prompt_tokens,
                prompt_cache_tokens=prompt_cache_tokens,
                prompt_audio_tokens=prompt_audio_tokens,
                completion_tokens=completion_tokens,
                completion_reasoning_tokens=completion_reasoning_tokens,
                completion_audio_tokens=completion_audio_tokens,
                completion_accepted_prediction_tokens=completion_accepted_prediction_tokens,
                completion_rejected_prediction_tokens=completion_rejected_prediction_tokens,
                total_tokens=total_tokens,
                status=status,
            )
            if not status:
                if retry < 2:
                    return call_chatgpt(
                        content, response_schema, post_id, base_prompt, retry=retry + 1
                    )
            return content
        return None
    except Exception as e:
        response_log = json.dumps({"error": str(e)})
        RequestLogService.create_request_log(
            post_id=post_id,
            ai_type="chatgpt",
            request=request_log,
            response=response_log,
            status=0,
        )
        return None


def translate_notifications_batch(notifications_batch):
    try:
        print(f"chatgpt_api_key{chatgpt_api_key}")
        client = OpenAI(api_key=chatgpt_api_key)

        assistant_id = "asst_rBXxdDDCdHuv3UxNDTiHrxVv"

        # Format input cho GPT: ID + ná»™i dung
        prompt = "Báº¡n hÃ£y dá»‹ch cÃ¡c thÃ´ng bÃ¡o sau sang tiáº¿ng HÃ n Quá»‘c . Giá»¯ nguyÃªn ID vÃ  Ä‘Ãºng thá»© tá»±:\n"
        for n in notifications_batch:
            prompt += f"ID {n['id']}: {n['text']}\n"

        # Táº¡o thread
        thread = client.beta.threads.create()

        # Gá»­i tin nháº¯n vÃ o thread
        client.beta.threads.messages.create(
            thread.id,
            role="user",
            content=[{"type": "text", "text": prompt}],
        )

        # Táº¡o run
        run = client.beta.threads.runs.create(
            thread_id=thread.id, assistant_id=assistant_id
        )

        # Chá» pháº£n há»“i (timeout: 30s)
        timeout_seconds = 30
        start_time = time.time()
        while True:
            run = client.beta.threads.runs.retrieve(run.id, thread_id=thread.id)
            if run.status == "completed":
                break
            elif run.status in ["failed", "cancelled", "expired"]:
                raise Exception(f"Run status error: {run.status}")
            if time.time() - start_time > timeout_seconds:
                raise TimeoutError("GPT processing timeout.")
            time.sleep(1)

        # Láº¥y pháº£n há»“i
        messages = client.beta.threads.messages.list(thread.id)
        for message in messages:
            if message.role == "assistant" and message.content:
                # TrÃ­ch xuáº¥t ná»™i dung vÄƒn báº£n pháº£n há»“i
                translated_text = message.content[0].text.value
                return parse_translations(translated_text)

        return {}

    except OpenAIError as e:
        logger.error(f"[OpenAI API Error xxxxxxxxxx] {e}")
        print(f"[OpenAI API Error] {e}")
    except TimeoutError as e:
        logger.error(f"[Timeout Error] {e}")
        print(f"[Timeout Error] {e}")
    except Exception as e:
        logger.error(f"[Unhandled  Error] {e}")
        print(f"[Unhandled Error] {e}")

    # Náº¿u lá»—i, tráº£ vá» dict rá»—ng
    return {}


def parse_translations(response_text):
    """
    PhÃ¢n tÃ­ch pháº£n há»“i tá»« GPT Ä‘á»ƒ láº¥y láº¡i ID vÃ  báº£n dá»‹ch.
    VÃ­ dá»¥ Ä‘áº§u vÃ o:
    ID 101: CÃ³ báº£n cáº­p nháº­t má»›i cho thiáº¿t bá»‹ cá»§a báº¡n.
    ID 102: Pin yáº¿u.
    """
    translations = {}
    lines = response_text.strip().split("\n")
    for line in lines:
        match = re.match(r"ID\s*(\d+):\s*(.+)", line)
        if match:
            notif_id = int(match.group(1))
            translated_text = match.group(2).strip()
            translations[notif_id] = translated_text
    return translations
