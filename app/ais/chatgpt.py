import json
from openai import OpenAI
from app.services.request_log import RequestLogService
import os

chatgpt_api_key = os.environ.get("CHATGPT_API_KEY") or ""


def call_chatgpt_create_caption(images=[], data={}, post_id=0):

    prompt = """ğŸ“Œ ìš”ì²­ ì‚¬í•­: ì—…ë¡œë“œëœ ì´ë¯¸ì§€ë¥¼ ì°¸ê³ í•˜ì—¬ ì œí’ˆì„ í™ë³´í•˜ëŠ” ìˆí¼(Shorts, TikTok) ìŠ¤íƒ€ì¼ì˜ ì˜ìƒ ì½˜í…ì¸ ë¥¼ ì œì‘í•  ìˆ˜ ìˆë„ë¡ ì•„ë˜ ìš”ì†Œë“¤ì„ ìƒì„±í•´ ì£¼ì„¸ìš”.

ì œëª© (Title): ì§§ê³  ê°•ë ¬í•˜ë©° ì œí’ˆì˜ í•µì‹¬ ê°€ì¹˜ë¥¼ ê°•ì¡°í•˜ëŠ” ë¬¸êµ¬
í´ë¦­ì„ ìœ ë„í•˜ëŠ” í¥ë¯¸ë¡œìš´ í‘œí˜„ í¬í•¨

ìº¡ì…˜ ëª©ë¡ (CAPTION_COUNTê°œ): ê° ìº¡ì…˜ì€ gTTSë¥¼ í†µí•´ ìƒì„±ëœ ì˜¤ë””ì˜¤ê°€ ì•½ 5ì´ˆ ë™ì•ˆ ì¬ìƒë  ìˆ˜ ìˆë„ë¡ êµ¬ì„±
ì„íŒ©íŠ¸ ìˆëŠ” ë¬¸ì¥ìœ¼ë¡œ ì‹œì²­ìì˜ ê´€ì‹¬ì„ ëŒì–´ì•¼ í•¨
ë§ˆì§€ë§‰ì—ëŠ” í–‰ë™ ìœ ë„ë¥¼ ìœ„í•œ Call-to-Action(CTA) í¬í•¨

í•´ì‹œíƒœê·¸ ëª©ë¡: ì œí’ˆ ë° íƒ€ê²Ÿ ê³ ê°ì¸µì— ë§ëŠ” ì¸ê¸° í•´ì‹œíƒœê·¸ ì„ ì •
ê°œë³„ í•´ì‹œíƒœê·¸ë¡œ ì œê³µí•˜ë©°, ìº¡ì…˜ê³¼ ë¶„ë¦¬í•  ê²ƒ

DCì¸ì‚¬ì´ë“œ ìŠ¤íƒ€ì¼ ê²Œì‹œê¸€ (200ì ì´ë‚´): ìœ ë¨¸ëŸ¬ìŠ¤í•˜ê³  ë„ë°œì ì¸ ë¬¸ì²´ ì‚¬ìš©
ì»¤ë®¤ë‹ˆí‹° íŠ¹ìœ ì˜ ë°ˆ(meme)ê³¼ ìœ í–‰ì–´ í™œìš©
ëŒ“ê¸€ ë°˜ì‘ì„ ìœ ë„í•  ìˆ˜ ìˆë„ë¡ êµ¬ì„±

ğŸ“Œ ì œí’ˆ ì •ë³´: ì œí’ˆëª…: {name}
ê°€ê²©: {price}
ì œí’ˆ ì„¤ëª…: {description}
íŒë§¤ì²˜: {store_name}
ì œí’ˆ ë§í¬: {base_url}
ì œí’ˆ ì†Œê°œ: {text}

ğŸ“Œ ìƒì„± ì¡°ê±´: âœ… ì œëª©: ì§§ê³  ê°•ë ¬í•˜ê²Œ! (ì˜ˆ: â€œì´ê±¸ ì•ˆ ì‚¬ë©´ í›„íšŒê°!â€)
ì˜ìƒ ìŠ¤íƒ€ì¼ì— ë§ëŠ” í†¤ & í…ì…˜ ìœ ì§€

âœ… ìº¡ì…˜: ì´ CAPTION_COUNTê°œì˜ ë¬¸ì¥ì„ gTTS ì˜¤ë””ì˜¤ê°€ ê°ê° 5ì´ˆ ë¶„ëŸ‰ìœ¼ë¡œ ì¬ìƒë  ìˆ˜ ìˆë„ë¡ ì‘ì„±
íŠ¸ë Œë””í•œ í‘œí˜„, ê°íƒ„ì‚¬, ê°ì„±ì ì¸ ìš”ì†Œ í¬í•¨
ë§ˆì§€ë§‰ì— ê°•ë ¥í•œ CTA í¬í•¨ (ì˜ˆ: â€œì§€ê¸ˆ êµ¬ë§¤í•˜ëŸ¬ ê°€ê¸°!â€)

âœ… í•´ì‹œíƒœê·¸: ì œí’ˆêµ°ê³¼ ê´€ë ¨ëœ í•´ì‹œíƒœê·¸ ì„ ì •
ìº¡ì…˜ê³¼ ë¶„ë¦¬ëœ ê°œë³„ ëª©ë¡ìœ¼ë¡œ ì œê³µ

âœ… DCì¸ì‚¬ì´ë“œ ìŠ¤íƒ€ì¼ ê²Œì‹œê¸€: 250ì ì´ë‚´, í•µì‹¬ ë©”ì‹œì§€ê°€ ë°”ë¡œ ì „ë‹¬ë˜ë„ë¡ ì‘ì„±
ê°•í•œ ì–´ì¡°, ë°ˆ(meme) ìš”ì†Œ, ìœ ë¨¸ ì½”ë“œ ë°˜ì˜
ë§ˆì¹˜ ì»¤ë®¤ë‹ˆí‹°ì—ì„œ ì‹¤ì œë¡œ ì‘ì„±ëœ ê¸€ì²˜ëŸ¼ ìì—°ìŠ¤ëŸ½ê²Œ êµ¬ì„±

ğŸ“Œ ì¶œë ¥ í˜•ì‹: âŒ Markdown ì‚¬ìš© ê¸ˆì§€ (ìˆœìˆ˜ í…ìŠ¤íŠ¸ë§Œ ë°˜í™˜)
âŒ ê¸°íƒ€ íŠ¹ìˆ˜ ë¬¸ì ì‚¬ìš© ê¸ˆì§€

ì´ í”„ë¡¬í”„íŠ¸ë¥¼ í™œìš©í•˜ë©´ ë”ìš± ê°•ë ¬í•˜ê³  íš¨ê³¼ì ì¸ SNS ì½˜í…ì¸ ë¥¼ ì œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤! ğŸš€
"""
    prompt = replace_prompt_with_data(prompt, data)

    prompt = prompt.replace("CAPTION_COUNT", str(len(images)))

    content = [{"type": "text", "text": prompt}]
    for image in images:
        content.append({"type": "image_url", "image_url": {"url": image}})

    response_schema = {
        "name": "response_schema",
        "schema": {
            "type": "object",
            "properties": {
                "response": {
                    "type": "object",
                    "properties": {
                        "title": {
                            "type": "string",
                            "description": "The title of the response.",
                        },
                        "content": {
                            "type": "string",
                            "description": "The content of the response.",
                        },
                        "captions": {
                            "type": "array",
                            "description": "A list of captions associated with the response.",
                            "items": {
                                "type": "string",
                                "description": "A caption string.",
                            },
                        },
                        "hashtag": {
                            "type": "string",
                            "description": "A hashtag associated with the response.",
                        },
                    },
                    "required": ["title", "content", "captions", "hashtag"],
                    "additionalProperties": False,
                }
            },
            "required": ["response"],
            "additionalProperties": False,
        },
        "strict": True,
    }

    return call_chatgpt(content, response_schema, post_id)


def call_chatgpt_create_blog(images=[], data={}, post_id=0):
    prompt = """ì—…ë¡œë“œëœ ì´ë¯¸ì§€ë“¤ì„ ì°¸ê³ í•˜ì—¬, ì œí’ˆì˜ ë‹¤ìŒ ì„¸ë¶€ ì •ë³´ë¥¼ ë°˜ì˜í•œ **ë¸”ë¡œê·¸ ê²Œì‹œê¸€**ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”.
ì œí’ˆ ê´€ë ¨ ì •ë³´:
- ì œí’ˆëª…: {name}
- ê°€ê²©: {price}
- ì œí’ˆ ì„¤ëª…: {description}
- íŒë§¤ì²˜: {store_name}
- ì œí’ˆ ë§í¬: {base_url}
- ì œí’ˆ ì†Œê°œ: {text}

ì¡°ê±´:
- ê²Œì‹œê¸€ì€ ì•½ 1200ì ì •ë„ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.
- ì œí’ˆì— ëŒ€í•œ ìì„¸í•œ ì„¤ëª…, ì¥ì , ì‚¬ìš© ë°©ë²• ë“±ì„ í¬í•¨í•˜ì—¬ ë…ìê°€ ê´€ì‹¬ì„ ê°€ì§ˆ ìˆ˜ ìˆë„ë¡ ì¹œê·¼í•˜ê³  ì„¤ë“ë ¥ ìˆê²Œ ì‘ì„±í•´ ì£¼ì„¸ìš”.
- ë¸”ë¡œê·¸ ê²Œì‹œê¸€ì€ **HTML í˜•ì‹**ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.
- ê²Œì‹œê¸€ ìƒë‹¨ì— ì‚¬ìš©ìì˜ ê´€ì‹¬ì„ ëŒ ìˆ˜ ìˆëŠ” **ë§¤ë ¥ì ì¸ ì œëª©**ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”.
- ì œí’ˆì˜ ì´ë¯¸ì§€ëŠ” ì—…ë¡œë“œëœ ì´ë¯¸ì§€ì—ì„œ ì„ íƒí•˜ì—¬ ì ì ˆí•œ ìœ„ì¹˜ì— ì‚½ì…í•´ ì£¼ì„¸ìš”.
- ê° ì´ë¯¸ì§€ì˜ `src`ëŠ” `IMAGE_URL_index` í˜•íƒœë¡œ ì‘ì„±ë˜ì–´ì•¼ í•˜ë©°, `index`ëŠ” `0`ë¶€í„° COUNT_IMAGE ê¹Œì§€ì˜ ìˆ«ìë¡œ ëŒ€ì²´ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
- ê²Œì‹œê¸€ ë‚´ìš©ê³¼ í•¨ê»˜, ë³¸ë¬¸ ë‚´ìš©ì„ ìš”ì•½í•œ **ìš”ì•½ë¬¸**ë„ ìƒì„±í•´ ì£¼ì„¸ìš”.
- **ìš”ì•½ë¬¸ì€ 300~350ì ì´ë‚´ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”. (ì°¸ê³ : ê¸€ì ìˆ˜ ì œí•œì€ ìš”ì•½ë¬¸ì—ë§Œ ì ìš©ë˜ë©°, ë³¸ë¬¸ì€ ì•½ 1200ì ê°€ì´ë“œë¼ì¸ì— ë”°ë¦…ë‹ˆë‹¤.)**
- ìš”ì•½ì˜ ë‚´ìš©ì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±ë˜ì–´ì•¼ í•˜ë©°, ê²°ê³¼ëŠ” ìˆœìˆ˜í•œ ë¬¸ìì—´ë¡œë§Œ ë°˜í™˜ë˜ì–´ì•¼ í•©ë‹ˆë‹¤
"""
    prompt = prompt.replace("COUNT_IMAGE", str(len(images)))

    prompt = replace_prompt_with_data(prompt, data)

    content = [{"type": "text", "text": prompt}]
    for image in images:
        content.append({"type": "image_url", "image_url": {"url": image}})

    response_schema = {
        "name": "response_schema",
        "schema": {
            "type": "object",
            "properties": {
                "response": {
                    "type": "object",
                    "properties": {
                        "title": {
                            "type": "string",
                            "description": "The title of the response.",
                        },
                        "summarize": {
                            "type": "string",
                            "description": "A summary or brief overview of the content.",
                        },
                        "content": {
                            "type": "string",
                            "description": "The main content of the response.",
                        },
                    },
                    "required": ["title", "summarize", "content"],
                    "additionalProperties": False,
                }
            },
            "required": ["response"],
            "additionalProperties": False,
        },
        "strict": True,
    }

    return call_chatgpt(content, response_schema, post_id)


def call_chatgpt_create_social(images=[], data={}, post_id=0):
    prompt = """[ì—­í• ]
ë‹¹ì‹ ì€ 20~30ëŒ€ ì»¤ë®¤ë‹ˆí‹°ì—ì„œ ìœ í–‰í•˜ëŠ” ì–¸ì–´ë¥¼ í™œìš©í•˜ëŠ” ë°”ì´ëŸ´ ë§ˆì¼€í„°ì…ë‹ˆë‹¤. ì œí’ˆì„ ì§ì ‘ ì„¤ëª…í•˜ì§€ ì•Šê³  ìì—°ìŠ¤ëŸ½ê²Œ ê´€ì‹¬ì„ ìœ ë„í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ SNS ì½˜í…ì¸ ë¥¼ ìƒì„±í•˜ì„¸ìš”. íŠ¹íˆ "DCì¸ì‚¬ì´ë“œ" ì»¤ë®¤ë‹ˆí‹°ì˜ ë§íˆ¬ë¥¼ ë°˜ì˜í•˜ì—¬ ì‘ì„±í•˜ì„¸ìš”.

[ì…ë ¥ ì •ë³´]

ì œí’ˆëª…: {name}
ê°€ê²©: {price}
ì œí’ˆ ì„¤ëª…: {description}
íŒë§¤ì²˜: {store_name}
ì œí’ˆ ë§í¬: {base_url}
ì´ë¯¸ì§€ ê°œìˆ˜: {image_count}
ì œí’ˆ ì†Œê°œ: {text}
[ìš”êµ¬ ì‚¬í•­]

SNS ê²Œì‹œê¸€ ì‘ì„±
Facebook: ì‚¬ëŒë“¤ì´ ê´€ì‹¬ì„ ê°€ì§€ê²Œ í•˜ê³ , ëŒ“ê¸€ê³¼ ê³µìœ ë¥¼ ìœ ë„í•˜ëŠ” ì „ì²´ ê²Œì‹œê¸€ì„ ì‘ì„± (ìµœì†Œ 160ì).
Instagram: ì§§ê³  ê°•ë ¬í•œ ë©”ì‹œì§€ì™€ í•´ì‹œíƒœê·¸ë¥¼ í¬í•¨í•œ ì „ì²´ ê²Œì‹œê¸€ì„ ì‘ì„± (ìµœì†Œ 160ì).
ì´ë¯¸ì§€ë³„ ìº¡ì…˜ ì‘ì„±
ì²« ë²ˆì§¸ ì´ë¯¸ì§€: ì œí’ˆì„ ì§ì ‘ ì–¸ê¸‰í•˜ì§€ ì•Šê³ , ê¶ê¸ˆì¦ì„ ìœ ë°œí•˜ëŠ” í•œ ì¤„ì§œë¦¬ ë°”ì´ëŸ´ ë¬¸êµ¬ ì‘ì„±.
ë‘ ë²ˆì§¸ë¶€í„° {image_count}ë²ˆì§¸ ì´ë¯¸ì§€:
ìœ í–‰í•˜ëŠ” ì»¤ë®¤ë‹ˆí‹° ë§íˆ¬ë¥¼ í™œìš©í•˜ì—¬, ê°€ìƒì˜ ìƒí™©ì„ ì„¤ì •í•œ í›„ ì œí’ˆì˜ ë§¤ë ¥ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°í•˜ëŠ” íŠ¸ë Œë””í•œ ë‚´ìš©ì„ ì‘ì„±.
ì§ì„¤ì ì¸ ê´‘ê³  ë¬¸êµ¬ë¥¼ ë°°ì œí•˜ê³ , êµ¬ë§¤ ìš•êµ¬ë¥¼ ìê·¹í•˜ëŠ” ê³µê°í˜• ì½˜í…ì¸ ë¡œ êµ¬ì„±.
í•´ì‹œíƒœê·¸:
ê° ì†Œì…œ ë¯¸ë””ì–´ ê²Œì‹œê¸€ê³¼ ì´ë¯¸ì§€ ìº¡ì…˜ì— SNSì—ì„œ ìœ í–‰í•˜ëŠ” í•´ì‹œíƒœê·¸ë¥¼ ì ì ˆíˆ ì¶”ê°€.
[ì¶œë ¥ í˜•ì‹]

ì „ì²´ ê²Œì‹œê¸€ ë‚´ìš©: Facebook ë° Instagramìš© ê²Œì‹œê¸€ì„ ê°ê° ë³„ë„ë¡œ ì‘ì„± (ê°ê° ìˆœìˆ˜í•œ í…ìŠ¤íŠ¸ë¡œ ë°˜í™˜).
ì´ë¯¸ì§€ë³„ ìº¡ì…˜:
ì²« ë²ˆì§¸ ì´ë¯¸ì§€: í˜¸ê¸°ì‹¬ì„ ìœ ë°œí•˜ëŠ” í•œ ì¤„ì§œë¦¬ ë°”ì´ëŸ´ ë¬¸êµ¬.
ë‘ ë²ˆì§¸ë¶€í„° {image_count}ë²ˆì§¸ ì´ë¯¸ì§€: ê°€ìƒì˜ ìƒí™©ì„ ë°”íƒ•ìœ¼ë¡œ í•œ ë°”ì´ëŸ´ ìŠ¤íƒ€ì¼ì˜ ì„¤ëª….
ê²°ê³¼ëŠ” ìˆœìˆ˜í•œ í…ìŠ¤íŠ¸ë¡œë§Œ ë°˜í™˜ (ì½”ë“œë‚˜ ë³„ë„ì˜ í¬ë§· ì—†ìŒ).
[ì˜ˆì‹œ ì¶œë ¥]

â–  Social Network ê²Œì‹œê¸€:
"ìš”ì¦˜ ì´ê±° ì—†ìœ¼ë©´ í—ˆì „í•˜ë‹¤! ì¹œêµ¬ë“¤ì´ ë‹¤ ì‚¬ìš©í•œë‹¤ê³  í•˜ëŠ” ê¿€í…œ, ë‚˜ë„ ì¨ë³´ê³  ì™„ì „ ë°˜í–ˆì–´. ìì„¸í•œ ì •ë³´ëŠ” ì—¬ê¸°ì—ì„œ í™•ì¸í•´ë´~ {base_url}"

â–  Hashtags:
#í•«í…œ #ìš”ì¦˜ëŒ€ì„¸ #ì¶”ì²œí…œ"

â–  ì´ë¯¸ì§€ë³„ ìº¡ì…˜:
[ì²« ë²ˆì§¸ ì´ë¯¸ì§€ - ë°”ì´ëŸ´ ë¬¸êµ¬]:
"ì´ê±° ì—†ìœ¼ë©´ ë‹¤ë¦¬ ê¸¸ì´ -5cm íš¨ê³¼ì„"

[ë‘ ë²ˆì§¸ ì´ë¯¸ì§€ - ë°”ì´ëŸ´ ì„¤ëª…]:
"ì¹œêµ¬ê°€ ì´ê±° ì“°ê³  ë‹¤ë‹ˆê¸¸ë˜ ë­”ì§€ ë¬¼ì–´ë´¤ë”ë‹ˆ, ì¨ë³´ë‹ˆê¹Œ ã„¹ã…‡ ì¸ì •. ìš”ì¦˜ ëŒ€ì„¸ì„ ã…‡ã…‡"

[ì„¸ ë²ˆì§¸ ì´ë¯¸ì§€ - ë°”ì´ëŸ´ ì„¤ëª…]:
"ì²˜ìŒì—ëŠ” ê·¸ëƒ¥ í˜¸ê¸°ì‹¬ìœ¼ë¡œ ì‹œì‘í–ˆëŠ”ë°, í•œ ë²ˆ ì¨ë³´ê³  ë‚˜ë‹ˆ ì¸ìƒí…œ í™•ì •"

[ë„¤ ë²ˆì§¸ ì´ë¯¸ì§€ - ë°”ì´ëŸ´ ì„¤ëª…]:
"DCì¸ì‚¬ì´ë“œ ê°¤ëŸ¬ë¦¬ì—ì„œë„ ë²Œì¨ ì…ì†Œë¬¸ë‚œ ê¿€í…œ, ì‚¬ë†“ê³  í›„íšŒ ì—†ëŠ” ì„ íƒ!"

[ë‹¤ì„¯ ë²ˆì§¸ ì´ë¯¸ì§€ - ë°”ì´ëŸ´ ì„¤ëª…]:
"ë‚˜ë§Œ ì•Œê³  ì‹¶ì—ˆë˜ ë¹„ë°€í…œ, ì´ì   ëª¨ë‘ê°€ ì•Œì•„ì•¼ í•  ê¿€ì¡°í•©â€¦"

[ë…¸íŠ¸]

ì „ì²´ ê²Œì‹œê¸€ê³¼ ì´ë¯¸ì§€ ìº¡ì…˜ì€ ë³„ê°œë¡œ ì‘ì„±ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
ì œí’ˆ ì§ì ‘ ì„¤ëª…ì„ í”¼í•˜ê³ , ìì—°ìŠ¤ëŸ¬ìš´ ìŠ¤í† ë¦¬í…”ë§ê³¼ ê³µê°ì„ ìœ ë„í•˜ëŠ” ë‚´ìš©ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
20~30ëŒ€ ì»¤ë®¤ë‹ˆí‹°ì—ì„œ ìœ í–‰í•˜ëŠ” ì–¸ì–´ì™€ ìŠ¤íƒ€ì¼ì„ ì ê·¹ í™œìš©í•˜ì„¸ìš”."""

    data["image_count"] = len(images)

    prompt = replace_prompt_with_data(prompt, data)

    content = [{"type": "text", "text": prompt}]
    for image in images:
        content.append({"type": "image_url", "image_url": {"url": image}})

    response_schema = {
        "name": "response_schema",
        "schema": {
            "type": "object",
            "properties": {
                "response": {
                    "type": "object",
                    "properties": {
                        "post": {
                            "type": "string",
                            "description": "The content of the post.",
                        },
                        "captions": {
                            "type": "array",
                            "description": "A list of captions associated with the response.",
                            "items": {
                                "type": "string",
                                "description": "A caption string.",
                            },
                        },
                        "hashtag": {
                            "type": "string",
                            "description": "The associated hashtag.",
                        },
                    },
                    "required": ["post", "captions", "hashtag"],
                    "additionalProperties": False,
                }
            },
            "required": ["response"],
            "additionalProperties": False,
        },
        "strict": True,
    }

    return call_chatgpt(content, response_schema, post_id)


def replace_prompt_with_data(prompt, data):
    prompt = prompt.format(**data)
    return prompt


def call_chatgpt(content, response_schema, post_id=0):
    client = OpenAI(api_key=chatgpt_api_key)
    model = "gpt-4o-mini"

    request_log = json.dumps(
        {
            "model": model,
            "messages": [{"role": "user", "content": content}],
            "response_format": {
                "type": "json_schema",
                "json_schema": response_schema,
            },
            "max_tokens": 3000,
            "temperature": 0.9,
        }
    )

    try:
        response = client.chat.completions.create(
            model=model,
            messages=[
                {
                    "role": "user",
                    "content": content,
                }
            ],
            response_format={
                "type": "json_schema",
                "json_schema": response_schema,
            },
            max_tokens=5000,
            temperature=0.9,
        )
        response_log = json.dumps(response.to_dict())

        if response:
            content = response.choices[0].message.content or None
            usage = response.usage
            prompt_tokens = usage.prompt_tokens
            completion_tokens = usage.completion_tokens
            prompt_cache_tokens = usage.prompt_tokens_details.cached_tokens
            prompt_audio_tokens = usage.prompt_tokens_details.audio_tokens
            completion_reasoning_tokens = (
                usage.completion_tokens_details.reasoning_tokens
            )
            completion_audio_tokens = usage.completion_tokens_details.audio_tokens
            completion_accepted_prediction_tokens = (
                usage.completion_tokens_details.accepted_prediction_tokens
            )
            completion_rejected_prediction_tokens = (
                usage.completion_tokens_details.rejected_prediction_tokens
            )
            total_tokens = usage.total_tokens

            status = 1
            if not content:
                status = 0
            RequestLogService.create_request_log(
                post_id=post_id,
                ai_type="chatgpt",
                request=request_log,
                response=response_log,
                prompt_tokens=prompt_tokens,
                prompt_cache_tokens=prompt_cache_tokens,
                prompt_audio_tokens=prompt_audio_tokens,
                completion_tokens=completion_tokens,
                completion_reasoning_tokens=completion_reasoning_tokens,
                completion_audio_tokens=completion_audio_tokens,
                completion_accepted_prediction_tokens=completion_accepted_prediction_tokens,
                completion_rejected_prediction_tokens=completion_rejected_prediction_tokens,
                total_tokens=total_tokens,
                status=status,
            )
            return content
        return None
    except Exception as e:
        response_log = json.dumps({"error": str(e)})
        RequestLogService.create_request_log(
            post_id=post_id,
            ai_type="chatgpt",
            request=request_log,
            response=response_log,
            status=0,
        )
        return None
